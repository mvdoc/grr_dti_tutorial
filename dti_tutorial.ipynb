{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "85f06de3-d710-4515-9c0b-3533797e7dde"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "cce2c2a6-b8ca-495a-b73e-b9fadab19847"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><font size=\"48\"><h1>DTI Tutorial</h1></font></center>\n",
    "<br>\n",
    "# Matteo Visconti di Oleggio Castello üáÆüáπ <br>Manon de Villemejane üá´üá∑\n",
    "### Day of GRR‚ÄîJun 2, 2017\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is Diffusion Weighted Imaging?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](rokem_fig1.png)\n",
    "\n",
    "Image from [Rokem et al., 2017](http://jov.arvojournals.org/article.aspx?articleid=2603187), released under CC-BY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "From [Rokem et al., 2017](http://jov.arvojournals.org/article.aspx?articleid=2603187):\n",
    "\n",
    "> Inferences about white matter from measurements of water diffusion. <br>\n",
    "(A) Micrograph of the human optic nerve. Left, bundles of myelinated axonal fascicles from the human optic nerve (image courtesy of Dr. George Bartzokis). Right, cartoon example of anisotropic water diffusion restriction by white matter fascicles. Water diffuses further along the direction of the ‚Äútube‚Äù (Pierpaoli & Basser, 1996). <br>\n",
    "(B) Example of diffusion-weighted magnetic resonance measurements in a single slice of a living human brain. The same brain slice is shown as imaged with two different diffusion weighting directions. Diffusion weighting directions are shown by the inset arrows. The white highlighted area indicates the approximate location of part of the optic radiation (OR). The longitudinal shape of the OR appears as a local darkening of the MRI image when the diffusion-weighting gradient is aligned with the direction of the myelinated fascicles within the OR (right-hand panel)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](rokem_fig3.png)\n",
    "Image from [Rokem et al., 2017](http://jov.arvojournals.org/article.aspx?articleid=2603187), released under CC-BY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "From [Rokem et al., 2017](http://jov.arvojournals.org/article.aspx?articleid=2603187):\n",
    "\n",
    "> Relationship between dMRI signals, voxel models of diffusion, and tractography. <br>\n",
    "(A) An axial brain slice. Two voxel locations are indicated in blue and green. The white rectangle indicates the location of the images in panel C. <br>\n",
    "(B) Measured diffusion-weighted MRI in the colored locations in panel A. Left column: Diffusion signal for the green (top) and blue (bottom) locations rendered as 3-D surfaces with the color map indicating the intensity of the diffusion-weighted signal in each direction (red is low signal or high diffusion and yellow-white is high signal or low diffusion). Middle column: The 3-D Gaussian distribution of diffusion distance, estimated from the DTM for the signal to the left. The major axis of the ellipsoid indicates the PDD estimated by the tensor model, different for the two voxels. Right column: fODF estimated by a fascicle mixture model: The constrained spherical deconvolution (CSD) model (Tournier et al., 2007) from the signal to its left. CSD indicates several probable directions of fascicles. Color map indicates likelihood of the presence of fascicles in a direction. <br>\n",
    "(C) Top panel: Detail of the region highlighted in panel A (white frame) with example of two seeds randomly placed within the white matter and used to generate the fascicles in the bottom panel. Bottom panel: Fits of the CSD model to each voxel and two example tracks (streamlines) crossing at the location of the centrum semiovale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Time to play with some data\n",
    "- I will put the notebook and slides up: don't worry about the code!\n",
    "- It's more important to understand the steps.\n",
    "- Huge thanks to Rachel and Jessi for sharing their data with me!\n",
    "\n",
    "# Caveat \n",
    "- This is an exploration: we don't know yet if this is the **optimal** way to analyze DWI data (most likely it's not)\n",
    "- It's been very useful for us to understand the data better\n",
    "\n",
    "# Source\n",
    "- Most of the code here comes from [dipy](http://nipy.org/dipy/)'s tutorials\n",
    "![](img/dipy-logo.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "a4b7ff6e-d040-4d6b-895b-a91c2b1bb3a6"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!ls data/1005-faceperception/sub-sid000050/{anat,dwi}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1a0f7f57-24c9-4848-ab95-10855a3db536"
    }
   },
   "source": [
    "Once we converted the DICOMs to NIFTI in BIDS format, under the `dwi` directory we'll have four filetypes:\n",
    "\n",
    "1. \\*.nii.gz: nifti files with acquired data\n",
    "2. \\*.bval: *b* values\n",
    "3. \\*.bvec: vectors associated to *b* values\n",
    "4. \\*.json: file containing information on acquisition sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "9908e707-2ce6-411c-bbcb-7cc5b70f3f80"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# set up filenames\n",
    "dwi_fn = 'data/1005-faceperception/sub-sid000050/dwi/sub-sid000050_acq-30_run-10_dwi.nii.gz'\n",
    "bval_fn = dwi_fn.replace('nii.gz', 'bval')\n",
    "bvec_fn = dwi_fn.replace('nii.gz', 'bvec')\n",
    "\n",
    "# load image\n",
    "dwi = nib.load(dwi_fn)\n",
    "# get data and header\n",
    "dwi_d = dwi.get_data()\n",
    "dwi_h = dwi.header\n",
    "dwi_affine = dwi.affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "7328c449-8fef-4196-b806-a10f4b6fbec4"
    }
   },
   "outputs": [],
   "source": [
    "# shape of our 4D tensor\n",
    "print(dwi_d.shape)\n",
    "# voxel size\n",
    "print(dwi_h.get_zooms()[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9c18ce37-c287-4be0-88ce-11b9062355ae"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- The DWI data a 4D tensor (similar to fMRI)\n",
    "- The 4th dimension represents the direction of the gradient (same index as the bvec file) with the respective b-value (same index as the bval file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "21641029-f19b-49d3-ace7-5a53816fca00"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# load bvals and bvecs using dipy's tools\n",
    "from dipy.io import read_bvals_bvecs\n",
    "bvals, bvecs = read_bvals_bvecs(bval_fn, bvec_fn)\n",
    "\n",
    "from dipy.core.gradients import gradient_table\n",
    "gtab = gradient_table(bvals, bvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e9e251f2-d7b7-461e-9fda-2b69a5ebbb05"
    }
   },
   "outputs": [],
   "source": [
    "print(bvals[:10, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "73499ca3-fb10-4a0d-a1b6-9683ca8b4da8"
    }
   },
   "outputs": [],
   "source": [
    "print(bvecs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "8cc4b844-3ec2-4c83-be52-58205010750c"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(len(bvals), len(bvecs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2eacf70d-d7d3-4728-a2e0-5e5399057d88"
    }
   },
   "source": [
    "This sequence had 30 directions with constant $b$-value: 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "10035adc-ad74-444a-b939-e505a558a897"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for x, y, z in bvecs:\n",
    "    ax.plot_wireframe([0, x], [0, y], [0, z])\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.set_zlim(-1, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6245ec82-df1e-442d-8ef4-0322df035ff4"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "OK, now we can start analyzing our data. First, let's see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "82c77f22-f0a6-4297-a98d-2f1d2fceeb2d"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from dipy.segment.mask import median_otsu\n",
    "from dipy.core.histeq import histeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "b1fd2c01-71b9-43bf-8c88-4dd4e1169afc"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# just a handy function to plot\n",
    "def plot_axial(img, where=35, ax=None, mask=None):\n",
    "    if ax is None:\n",
    "        plotter = plt\n",
    "    else:\n",
    "        plotter = ax\n",
    "    img_ = img.copy()\n",
    "    if mask is not None:\n",
    "        img_[np.logical_not(mask)] = 0.\n",
    "    plotter.imshow(histeq(img_[:, :, where].T), origin='lower', \n",
    "                   cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d65ac395-3e5b-455b-ba6b-e621d20fdf65"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# First volume, with $b = 0$, i.e. no diffusion weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "6f83606b-332a-409b-af3d-63d8a435629b"
    }
   },
   "outputs": [],
   "source": [
    "plot_axial(dwi_d[:, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "64f3941c-a161-456b-af54-6a578b6f858a"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The plan\n",
    "\n",
    "1. Preprocessing\n",
    "    - Reslicing\n",
    "    - Skull stripping\n",
    "2. Tractography\n",
    "    - Fit tensor model\n",
    "    - Discover tracts\n",
    "3. Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reslicing\n",
    "\n",
    "- Many of the methods for tractography require isotropic voxels\n",
    "- I'm not sure about this, but I would think it's better to have isotropic voxels out of the scanner, since we have less reslicing\n",
    "- However, we can reslice easily in dipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Voxel size is {0}\".format(dwi.header.get_zooms()[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dipy.align.reslice import reslice\n",
    "new_zooms = (2., 2., 2.)\n",
    "dwi_d2, dwi_affine2 = reslice(dwi_d, dwi_affine, dwi.header.get_zooms()[:3], new_zooms)\n",
    "print(dwi_d.shape, dwi_d2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_axial(dwi_d2[:, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "02389823-b312-4fab-9f6c-99cbdbd4f6a0"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Skull stripping\n",
    "\n",
    "- We can use many fancy methods (FSL's `BET`, AFNI's `3dSkullStrip`, FreeSurfer...)\n",
    "- Instead, we'll use a super quick way of separating an image from the background, the so-called **Otsu's method**.<br>You can read more about it on [Wikipedia](https://en.wikipedia.org/wiki/Otsu%27s_method) if you are interested.\n",
    "- We are going to perform skull-stripping on the image with $b = 0$, because it has better contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "3b29396a-0522-45be-8f15-067da5cedfa4"
    }
   },
   "outputs": [],
   "source": [
    "# select the b0 data\n",
    "data_b0 = dwi_d2[:, :, :, 0].squeeze()\n",
    "# N.B. this values (2, 1, dilate=2) are completely ad-hoc. \n",
    "# do not use this for your research unless you know what you're doing.\n",
    "b0_mask, mask = median_otsu(data_b0, 2, 1, dilate=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a6ad3bc0-f5b5-41b1-bd15-07cad8efd579"
    }
   },
   "source": [
    "Let's see what we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "0f0ea61d-e256-4f10-a22c-6ca88a8214a6"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=((8, 6)))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    mask_ = None if i == 0 else mask\n",
    "    plot_axial(data_b0, ax=ax, mask=mask_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d7e6c07a-ff04-45a4-bcf9-aee3cb420401"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motion correction and eddy distortions (skipped)\n",
    "\n",
    "- At this point you should perform some sort of alignment to correct for motion\n",
    "- You should correct for \"eddy distortions\", i.e. distortions caused by the rapid change in gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "12245e3d-6b2d-4d62-84d8-f1ea4dd4cf3f"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, HTML\n",
    "Image(url='https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy?action=AttachFile&do=get&target=before_after_hcp_v4.gif', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "3417020b-d50d-49da-b98e-1468f482284e"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "for i in range(1, 31):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    plot_axial(dwi_d[:, :, :, i], ax=ax)\n",
    "    fig.savefig('img/dwi{0:02d}.png'.format(i))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "80ce3b42-bfe3-4ed0-b994-e4cdf5306c05"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sp.check_call(\"convert img/dwi*.png -trim -delay 10 img/dwi.gif\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6e266cb5-8710-4f67-bb95-f611805ab092"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src='img/dwi.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "1995dee3-daa6-4955-b1db-8e6e9bca2d14"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- BUT we don't have time, so we are going to skip it altogether. \n",
    "- It's also possible to perform some denoising, but for time constraints we are going to skip that too. Read more about it on the dipy tutorial [Denoise images using Non-Local Means (NLMEANS)](http://nipy.org/dipy/examples_built/denoise_nlmeans.html#example-denoise-nlmeans)\n",
    "\n",
    "It's time to run our model and get some tracts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tractography\n",
    "\n",
    "- In the end, we want to get nice pictures with tracts. To get there, we need two things:\n",
    "    1. Model the diffusion data per-voxel basis (think GLM), to get the most likely direction\n",
    "    2. Find the tracts\n",
    "<br>\n",
    "- For step 1 we are going to use the **Tensor Model**, but there are many other models\n",
    "- For step 2 we are going to use **deterministic tractography**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tensor Model\n",
    "This part is heavily based on the dipy tutorial [Reconstruction of the diffusion signal with the Tensor model](http://nipy.org/dipy/examples_built/reconst_dti.html#example-reconst-dti)\n",
    "\n",
    "So, what is this \"Tensor Model\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For each voxel, we are modeling the diffusion signal as follows:\n",
    "\n",
    "$$\\frac{S(\\mathbf{g},b)}{S_0} = e^{-b\\mathbf{g}^T\\mathbf{D}\\mathbf{g}}$$\n",
    "\n",
    "with our particular dataset, we will always have $b = 1,000$, and $\\mathbf{g}$ is just the rows we have in the bvec files, indicating the direction of the gradient.<br>See why we need bvals and bvecs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the end, we want to discover $\\mathbf{D}$, which is a matrix indicating the *diffusivity* along the three axis, with 6 free parameters to be estimated:\n",
    "\n",
    "$$   \\mathbf{D} = \\begin{pmatrix} D_{xx} & D_{xy} & D_{xz} \\\\\n",
    "                       D_{yx} & D_{yy} & D_{yz} \\\\\n",
    "                       D_{zx} & D_{zy} & D_{zz} \\\\ \\end{pmatrix}$$\n",
    "                       \n",
    "It's 6 parameters because we assume that $D_{xy} = D_{yx}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Enough math! Let's fit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import dipy.reconst.dti as dti\n",
    "\n",
    "# set up tensor model giving the bval/bvec information\n",
    "tenmodel = dti.TensorModel(gtab)\n",
    "\n",
    "# get masked data\n",
    "dwi_d2_masked = dwi_d2.copy()\n",
    "dwi_d2_masked[np.logical_not(mask)] = 0.\n",
    "\n",
    "# fit tensor model to masked data\n",
    "tenfit = tenmodel.fit(dwi_d2_masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can estimate the *Fractional Anisotropy*, an index of how directional each voxel is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Meaning:\n",
    "\n",
    "![Fractional Anistropy](FA.png)\n",
    "\n",
    "with $\\lambda_i$ eigenvalues of $\\mathbf{D}$\n",
    "\n",
    "image from https://openi.nlm.nih.gov/detailedresult.php?img=PMC3194768_kjr-12-651-g001&req=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from dipy.reconst.dti import fractional_anisotropy, color_fa, lower_triangular\n",
    "FA = fractional_anisotropy(tenfit.evals)\n",
    "# set nans to 0 (e.g., when there is not enough signal)\n",
    "FA[np.isnan(FA)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's check what we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_axial(FA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "Let's try to make something fancier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Get RGB colors indicating the direction from the eigen vectors\n",
    "FA = np.clip(FA, 0, 1)\n",
    "RGB = color_fa(FA, tenfit.evecs)\n",
    "\n",
    "from dipy.data import get_sphere\n",
    "sphere = get_sphere('symmetric724')\n",
    "\n",
    "from dipy.viz import fvtk\n",
    "ren = fvtk.ren()\n",
    "# zoom in into a nice area\n",
    "evals = tenfit.evals[45:75, 20:60, 35:36]\n",
    "evecs = tenfit.evecs[45:75, 20:60, 35:36]\n",
    "\n",
    "cfa = RGB[45:75, 20:60, 35:36]\n",
    "cfa /= cfa.max()\n",
    "\n",
    "fvtk.add(ren, fvtk.tensor(evals, evecs, cfa, sphere))\n",
    "fvtk.record(ren, n_frames=1, out_path='img/tensor_ellipsoids.png', size=(800, 800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is where we zoomed in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_axial(FA[45:75, 20:60, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And this is what we get:\n",
    "\n",
    "![Fancyness](img/tensor_ellipsoids.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tractography\n",
    "\n",
    "Before starting, it's a good idea to have a white-matter mask, so that we use only on white-matter voxels. \n",
    "\n",
    "We don't have time to go over the entire process, but this is what I did (you can see the alignment step in the notebook when you download it):\n",
    "\n",
    "1. FSL's `BET` to remove the skull\n",
    "2. FSL's `FAST` to segment white and gray matter\n",
    "3. dipy to align the brain to the DWI b0, and use the affine to align the white-matter mask to the DWI\n",
    "\n",
    "In the end, this is what you end up with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# The code for the alignment comes from dipy's tutorial\n",
    "# http://nipy.org/dipy/examples_built/affine_registration_3d.html\n",
    "\n",
    "from dipy.viz import regtools\n",
    "from dipy.data import fetch_stanford_hardi, read_stanford_hardi\n",
    "from dipy.data.fetcher import fetch_syn_data, read_syn_data\n",
    "from dipy.align.imaffine import (transform_centers_of_mass,\n",
    "                                 AffineMap,\n",
    "                                 MutualInformationMetric,\n",
    "                                 AffineRegistration)\n",
    "from dipy.align.transforms import (TranslationTransform3D,\n",
    "                                   RigidTransform3D,\n",
    "                                   AffineTransform3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# We want to align the anatomical to the DWI b0, so we can align also the mask\n",
    "# let's take the skull-stripped one\n",
    "static = np.squeeze(dwi_d2_masked[:, :, :, 0])\n",
    "static_grid2world = dwi_affine2\n",
    "# and now let's take the skull-stripped anatomical\n",
    "anat = nib.load('sub-sid000050_acq-MPRAGE_T1w_brain.nii.gz')\n",
    "moving = anat.get_data()\n",
    "moving_grid2world = anat.affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# no transformation applied, let's see where we're starting from\n",
    "identity = np.eye(4)\n",
    "affine_map = AffineMap(identity,\n",
    "                       static.shape, static_grid2world,\n",
    "                       moving.shape, moving_grid2world)\n",
    "resampled = affine_map.transform(moving)\n",
    "regtools.overlay_slices(static, resampled, None, 0,\n",
    "                        \"Static\", \"Moving\");\n",
    "regtools.overlay_slices(static, resampled, None, 1,\n",
    "                        \"Static\", \"Moving\");\n",
    "regtools.overlay_slices(static, resampled, None, 2,\n",
    "                        \"Static\", \"Moving\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# move only center of mass of the two images\n",
    "c_of_mass = transform_centers_of_mass(static, static_grid2world,\n",
    "                                      moving, moving_grid2world)\n",
    "\n",
    "transformed = c_of_mass.transform(moving)\n",
    "regtools.overlay_slices(static, transformed, None, 0,\n",
    "                        \"Static\", \"Transformed\");\n",
    "regtools.overlay_slices(static, transformed, None, 1,\n",
    "                        \"Static\", \"Transformed\");\n",
    "regtools.overlay_slices(static, transformed, None, 2,\n",
    "                        \"Static\", \"Transformed\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# use a fancier method using Mutual Information\n",
    "# see http://nipy.org/dipy/examples_built/affine_registration_3d.html\n",
    "nbins = 32\n",
    "sampling_prop = None\n",
    "metric = MutualInformationMetric(nbins, sampling_prop)\n",
    "\n",
    "# set up pyramids\n",
    "level_iters = [10000, 1000, 100]\n",
    "sigmas = [3.0, 1.0, 0.0]\n",
    "factors = [4, 2, 1]\n",
    "\n",
    "# set up affine registration\n",
    "affreg = AffineRegistration(metric=metric,\n",
    "                            level_iters=level_iters,\n",
    "                            sigmas=sigmas,\n",
    "                            factors=factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# first use only translation\n",
    "transform = TranslationTransform3D()\n",
    "params0 = None\n",
    "starting_affine = c_of_mass.affine\n",
    "translation = affreg.optimize(static, moving, transform, params0,\n",
    "                              static_grid2world, moving_grid2world,\n",
    "                              starting_affine=starting_affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "transformed = translation.transform(moving)\n",
    "regtools.overlay_slices(static, transformed, None, 0,\n",
    "                        \"Static\", \"Transformed\");\n",
    "regtools.overlay_slices(static, transformed, None, 1,\n",
    "                        \"Static\", \"Transformed\");\n",
    "regtools.overlay_slices(static, transformed, None, 2,\n",
    "                        \"Static\", \"Transformed\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# then allow also rotations, using the previous affine\n",
    "transform = RigidTransform3D()\n",
    "params0 = None\n",
    "starting_affine = translation.affine\n",
    "rigid = affreg.optimize(static, moving, transform, params0,\n",
    "                        static_grid2world, moving_grid2world,\n",
    "                        starting_affine=starting_affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "transformed = rigid.transform(moving)\n",
    "regtools.overlay_slices(static, transformed, None, 0,\n",
    "                        \"Static\", \"Transformed\");\n",
    "regtools.overlay_slices(static, transformed, None, 1,\n",
    "                        \"Static\", \"Transformed\");\n",
    "regtools.overlay_slices(static, transformed, None, 2,\n",
    "                        \"Static\", \"Transformed\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# finally allow also shear\n",
    "transform = AffineTransform3D()\n",
    "params0 = None\n",
    "starting_affine = rigid.affine\n",
    "affine = affreg.optimize(static, moving, transform, params0,\n",
    "                         static_grid2world, moving_grid2world,\n",
    "                         starting_affine=starting_affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "transformed = affine.transform(moving)\n",
    "regtools.overlay_slices(static, transformed, None, 0,\n",
    "                        \"Static\", \"Transformed\");\n",
    "regtools.overlay_slices(static, transformed, None, 1,\n",
    "                        \"Static\", \"Transformed\");\n",
    "regtools.overlay_slices(static, transformed, None, 2,\n",
    "                        \"Static\", \"Transformed\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# now we can apply the transformation to the white matter mask\n",
    "white_matter = nib.load('sub-sid000050_acq-MPRAGE_T1w_brain_seg_2.nii.gz')\n",
    "white_matter_data = white_matter.get_data()\n",
    "white_matter_transformed = affine.transform(white_matter_data, interp='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_axial(white_matter_transformed, where=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reconstructing Tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from dipy.tracking import utils\n",
    "from dipy.tracking.local import ThresholdTissueClassifier, LocalTracking\n",
    "from dipy.data import default_sphere\n",
    "from dipy.direction import peaks_from_model\n",
    "from dipy.tracking.local import LocalTracking\n",
    "from dipy.viz import fvtk\n",
    "from dipy.viz.colormap import line_colors\n",
    "from dipy.tracking.streamline import select_random_set_of_streamlines\n",
    "from dipy.io.trackvis import save_trk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# find out peaks from our model\n",
    "peaks = peaks_from_model(tenmodel, dwi_d2, default_sphere,\n",
    "                 relative_peak_threshold=.8,\n",
    "                 min_separation_angle=45,\n",
    "                 mask=white_matter_transformed, \n",
    "                 parallel=True, nbr_processes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# NB: we are using an identity affine because the original affine has some shearing\n",
    "# which causes LocalTracking to complain. We can use an identity (operating in voxel space)\n",
    "# as long as the resliced dataset (or the acquired one) has isotropic voxels\n",
    "eye_affine = np.eye(4)\n",
    "# first we need to set the seeds. we'll just have one seed for each voxel.\n",
    "# if you increase that, you will get more tracts\n",
    "seeds = utils.seeds_from_mask(white_matter_transformed, density=1, affine=eye_affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# then we build a \"tissue classifier\" to know when to stop with our tracts white from gray matter\n",
    "# it's very simple: whatever has an FA value greater than a threshold is considered white-matter\n",
    "classifier = ThresholdTissueClassifier(FA, .25)\n",
    "\n",
    "# next we build the streamlines\n",
    "streamlines = LocalTracking(peaks, classifier, seeds, eye_affine, step_size=.5)\n",
    "\n",
    "# streamlines is a generator, so we get a list to compute all of them\n",
    "streamlines = list(streamlines)\n",
    "# we select a random subset for visualization\n",
    "plot_streamlines = select_random_set_of_streamlines(streamlines, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the display objects.\n",
    "streamlines_actor = fvtk.line(plot_streamlines, line_colors(plot_streamlines))\n",
    "\n",
    "# Create the 3d display.\n",
    "r = fvtk.ren()\n",
    "fvtk.add(r, streamlines_actor)\n",
    "\n",
    "# Save still images for this static example. Or for interactivity use\n",
    "fvtk.record(r, n_frames=1, out_path='deterministic.png',\n",
    "            size=(800, 800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](deterministic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Demo with TrackVis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_trk('deterministic.trk', streamlines, dwi_affine2, dwi_d2.shape[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusion\n",
    "DWI is fun. I'm still learning, but dipy makes it really easy to play around. As far as we understood, these are the steps required for DTI\n",
    "\n",
    "1. Preprocess your DWI data\n",
    "    - Skull stripping/white matter mask\n",
    "    - Denoise\n",
    "    - Reslice to isotropic voxel size\n",
    "<br>    \n",
    "2. Run a model to obtain metrics indicating white matter direction; we used the simple Tensor Model, but alternatives are:\n",
    "    - Constrained Spherical Deconvolution\n",
    "    - Q-Ball Constant Solid Angle\n",
    "    - Sparse Fascicle Model\n",
    "    - etc...\n",
    "<br>    \n",
    "3. Run a tractography method, such as\n",
    "    - Deterministic Tractography (what we used)\n",
    "    - Probabilistic Tractography (perhaps better? I don't know, but I like it betterüëå)\n",
    "<br>    \n",
    "4. Validate your model\n",
    "    - See for example the [Linear Fascicle Evaluation (LiFE) algorithm](http://nipy.org/dipy/examples_built/linear_fascicle_evaluation.html#example-linear-fascicle-evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Acknowledgments\n",
    "\n",
    "Manon conducted the majority of this experimentation on her own!\n",
    "\n",
    "# Resources and References\n",
    "- dipy's example gallery: http://nipy.org/dipy/examples_index.html\n",
    "- Rokem, A., Takemura, H., Bock, A. S., Scherf, K. S., Behrmann, M., Wandell, B. A., ‚Ä¶ Pestilli, F. (2017). The visual white matter: The application of diffusion MRI and fiber tractography to vision science. [Journal of Vision](http://jov.arvojournals.org/article.aspx?articleid=2603187)\n",
    "- Wandell, B. A. (2016). Clarifying Human White Matter. Annual Review of Neuroscience, 39, 103‚Äì128. https://doi.org/10.1146/annurev-neuro-070815-013815\n",
    "- Soares, J. M., Marques, P., Alves, V., & Sousa, N. (2013). A hitchhiker‚Äôs guide to diffusion tensor imaging. Frontiers in Neuroscience, 7, 31. https://doi.org/10.3389/fnins.2013.00031\n",
    "- Collection of IPython notebooks by Ariel Rokem on DTI: https://github.com/arokem/visual-white-matter"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "nbpresent": {
   "slides": {
    "15d9bcba-0511-4da8-801e-862a46d321a0": {
     "id": "15d9bcba-0511-4da8-801e-862a46d321a0",
     "prev": null,
     "regions": {
      "6993215a-3177-43a1-8189-6074e1436739": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "d47a7e00-230e-4437-8a6e-4d75bfbefe41",
        "part": "whole"
       },
       "id": "6993215a-3177-43a1-8189-6074e1436739"
      }
     }
    },
    "4cd00b0c-4517-4cfb-bccc-b29a9c3142ee": {
     "id": "4cd00b0c-4517-4cfb-bccc-b29a9c3142ee",
     "prev": "15d9bcba-0511-4da8-801e-862a46d321a0",
     "regions": {
      "0c86d56b-e975-480f-a561-70bc4644fe54": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "3417020b-d50d-49da-b98e-1468f482284e",
        "part": "whole"
       },
       "id": "0c86d56b-e975-480f-a561-70bc4644fe54"
      },
      "145c15df-ea69-4a88-9fe1-0db20a673032": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "82c77f22-f0a6-4297-a98d-2f1d2fceeb2d",
        "part": "whole"
       },
       "id": "145c15df-ea69-4a88-9fe1-0db20a673032"
      },
      "21c942e4-8cab-4bd5-99f6-f7a916d2e920": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "b1fd2c01-71b9-43bf-8c88-4dd4e1169afc",
        "part": "whole"
       },
       "id": "21c942e4-8cab-4bd5-99f6-f7a916d2e920"
      },
      "24c1a20d-bd44-4971-8ae8-9d2c1c1b7f36": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "1a0f7f57-24c9-4848-ab95-10855a3db536",
        "part": "whole"
       },
       "id": "24c1a20d-bd44-4971-8ae8-9d2c1c1b7f36"
      },
      "2ed3ae85-5e18-4bb7-b84e-c6c049e6e0c8": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "9908e707-2ce6-411c-bbcb-7cc5b70f3f80",
        "part": "whole"
       },
       "id": "2ed3ae85-5e18-4bb7-b84e-c6c049e6e0c8"
      },
      "3051040c-a81e-4f7a-99ab-0af0a9e12b03": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "0f0ea61d-e256-4f10-a22c-6ca88a8214a6",
        "part": "whole"
       },
       "id": "3051040c-a81e-4f7a-99ab-0af0a9e12b03"
      },
      "4790f3ef-4f5a-47af-a267-1a76a748892b": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "d65ac395-3e5b-455b-ba6b-e621d20fdf65",
        "part": "whole"
       },
       "id": "4790f3ef-4f5a-47af-a267-1a76a748892b"
      },
      "479fb317-c100-4c41-a3a5-53a36e229a83": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "a6ad3bc0-f5b5-41b1-bd15-07cad8efd579",
        "part": "whole"
       },
       "id": "479fb317-c100-4c41-a3a5-53a36e229a83"
      },
      "50e9d7f6-8609-40eb-b554-4927eee15656": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "6e266cb5-8710-4f67-bb95-f611805ab092",
        "part": "whole"
       },
       "id": "50e9d7f6-8609-40eb-b554-4927eee15656"
      },
      "529787e0-7b53-4bb1-9747-207db9d9d969": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "10035adc-ad74-444a-b939-e505a558a897",
        "part": "whole"
       },
       "id": "529787e0-7b53-4bb1-9747-207db9d9d969"
      },
      "53503021-bc3c-4678-ac59-53c1c3bdf20a": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "3b29396a-0522-45be-8f15-067da5cedfa4",
        "part": "whole"
       },
       "id": "53503021-bc3c-4678-ac59-53c1c3bdf20a"
      },
      "5a33a6cb-7a1d-4b0f-84a8-152cf5bcf78e": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "ab11c476-fb0a-426a-a07e-5db8f74b30e7",
        "part": "whole"
       },
       "id": "5a33a6cb-7a1d-4b0f-84a8-152cf5bcf78e"
      },
      "5c3633be-93db-420b-91a5-e85ff8099bfe": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "9c18ce37-c287-4be0-88ce-11b9062355ae",
        "part": "whole"
       },
       "id": "5c3633be-93db-420b-91a5-e85ff8099bfe"
      },
      "64a3e958-b86d-4138-b13e-2389abea3e97": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "21641029-f19b-49d3-ace7-5a53816fca00",
        "part": "whole"
       },
       "id": "64a3e958-b86d-4138-b13e-2389abea3e97"
      },
      "6c09ffbe-8787-49db-9719-034440dd9ec0": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a4b7ff6e-d040-4d6b-895b-a91c2b1bb3a6",
        "part": "whole"
       },
       "id": "6c09ffbe-8787-49db-9719-034440dd9ec0"
      },
      "6c1304e9-4b31-4da3-9795-3cbbe71ad862": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "80ce3b42-bfe3-4ed0-b994-e4cdf5306c05",
        "part": "whole"
       },
       "id": "6c1304e9-4b31-4da3-9795-3cbbe71ad862"
      },
      "756bf099-6a07-4323-a676-7c386eecbaa5": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "d6465431-4c0a-4828-8509-5588f77d6739",
        "part": "whole"
       },
       "id": "756bf099-6a07-4323-a676-7c386eecbaa5"
      },
      "7a428b98-99f9-4fa1-9e7c-6821c416c120": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "37ec5028-6489-4030-9d22-ac07a80abd92",
        "part": "whole"
       },
       "id": "7a428b98-99f9-4fa1-9e7c-6821c416c120"
      },
      "83b64d1f-4a3b-4a70-aba5-71109ba6feda": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "d7e6c07a-ff04-45a4-bcf9-aee3cb420401",
        "part": "whole"
       },
       "id": "83b64d1f-4a3b-4a70-aba5-71109ba6feda"
      },
      "8436b347-b8de-49be-8e29-e1645be0cfc7": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "2eacf70d-d7d3-4728-a2e0-5e5399057d88",
        "part": "whole"
       },
       "id": "8436b347-b8de-49be-8e29-e1645be0cfc7"
      },
      "8a39eb5f-6863-4bab-a752-08a978b902f1": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "64f3941c-a161-456b-af54-6a578b6f858a",
        "part": "whole"
       },
       "id": "8a39eb5f-6863-4bab-a752-08a978b902f1"
      },
      "a59b5bf4-c094-49d5-9c53-65f0a75ef49a": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "73499ca3-fb10-4a0d-a1b6-9683ca8b4da8",
        "part": "whole"
       },
       "id": "a59b5bf4-c094-49d5-9c53-65f0a75ef49a"
      },
      "a8ead07e-4967-4e73-b217-284512be278d": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "6f83606b-332a-409b-af3d-63d8a435629b",
        "part": "whole"
       },
       "id": "a8ead07e-4967-4e73-b217-284512be278d"
      },
      "ab051011-0dbe-47ac-b5b5-1adb343822e1": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "02389823-b312-4fab-9f6c-99cbdbd4f6a0",
        "part": "whole"
       },
       "id": "ab051011-0dbe-47ac-b5b5-1adb343822e1"
      },
      "ad6dde30-e2ff-4a4e-89ca-d85c6d4286ab": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "8cc4b844-3ec2-4c83-be52-58205010750c",
        "part": "whole"
       },
       "id": "ad6dde30-e2ff-4a4e-89ca-d85c6d4286ab"
      },
      "c1d69954-1573-4927-9428-7ec04409b5b8": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "e9e251f2-d7b7-461e-9fda-2b69a5ebbb05",
        "part": "whole"
       },
       "id": "c1d69954-1573-4927-9428-7ec04409b5b8"
      },
      "d0fe7fc0-fc4f-461a-9d24-a9e4f671a2d7": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "6245ec82-df1e-442d-8ef4-0322df035ff4",
        "part": "whole"
       },
       "id": "d0fe7fc0-fc4f-461a-9d24-a9e4f671a2d7"
      },
      "d4e6e9a2-d065-49e1-8c4e-6318d079e1b7": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "7328c449-8fef-4196-b806-a10f4b6fbec4",
        "part": "whole"
       },
       "id": "d4e6e9a2-d065-49e1-8c4e-6318d079e1b7"
      },
      "e215b3c3-7ff2-45f6-9202-23fd8e903d65": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "12245e3d-6b2d-4d62-84d8-f1ea4dd4cf3f",
        "part": "whole"
       },
       "id": "e215b3c3-7ff2-45f6-9202-23fd8e903d65"
      },
      "fa096fc6-62a4-4265-9437-501a6f25ade8": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "4fb6a73a-73ce-4bd0-9249-e0776f65f9dd",
        "part": "whole"
       },
       "id": "fa096fc6-62a4-4265-9437-501a6f25ade8"
      },
      "fa31a669-da6b-431e-b56b-7441422365ba": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "1995dee3-daa6-4955-b1db-8e6e9bca2d14",
        "part": "whole"
       },
       "id": "fa31a669-da6b-431e-b56b-7441422365ba"
      },
      "fba60151-9394-44b1-8f63-dd40363dbd01": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "9f6211e8-2261-4921-b956-00a87639c144",
        "part": "whole"
       },
       "id": "fba60151-9394-44b1-8f63-dd40363dbd01"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
